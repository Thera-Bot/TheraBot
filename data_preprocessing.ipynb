{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: pandas in ./.local/lib/python3.10/site-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in ./.local/lib/python3.10/site-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: tzdata>=2022.7 in ./.local/lib/python3.10/site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in ./.local/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: scikit-learn in ./.local/lib/python3.10/site-packages (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in ./.local/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: joblib>=1.2.0 in ./.local/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.local/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: scipy>=1.6.0 in ./.local/lib/python3.10/site-packages (from scikit-learn) (1.13.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pandas\n",
        "%pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "A_gn7Ql4sh8I"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "raw_filename = '/home/symon/Desktop/TheraBot/emotion_dataset_raw.csv'\n",
        "cleaned_filename = '/home/symon/Desktop/TheraBot/cleaned_data.csv'\n",
        "filtered_filename = '/home/symon/Desktop/TheraBot/filtered_data.csv'\n",
        "training_filename = '/home/symon/Desktop/TheraBot/training_data.csv'\n",
        "validation_filename = '/home/symon/Desktop/TheraBot/validation_data.csv'\n",
        "validation_json = '/home/symon/Desktop/TheraBot/validation_data.json'\n",
        "training_json = '/home/symon/Desktop/TheraBot/training_data.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aTvqO7Ay_kF",
        "outputId": "848ad2f7-c8f7-4cb4-ae35-4e84c013ef00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['neutral' 'joy' 'sadness' 'fear' 'surprise' 'anger' 'shame' 'disgust']\n"
          ]
        }
      ],
      "source": [
        "# Load the dataset\n",
        "df = pd.read_csv(raw_filename)\n",
        "\n",
        "# get the unique emotions from the dataset\n",
        "unique_emotions = df['Emotion'].unique()\n",
        "print(unique_emotions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "FjpR-Uh1z7so"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       Emotion                                               Text\n",
            "1          joy    Sage Act upgrade on my to do list for tommorow.\n",
            "2      sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
            "3          joy   Such an eye ! The true hazel eye-and so brill...\n",
            "4          joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...\n",
            "6      sadness   .Couldnt wait to see them live. If missing th...\n",
            "...        ...                                                ...\n",
            "34786      joy    Tuesday woken up to Oscar and Cornet practice X\n",
            "34788      joy  The world didnt give it to me..so the world MO...\n",
            "34789    anger                           A man robbed me today . \n",
            "34791  sadness  I think about you baby, and I dream about you ...\n",
            "34792    anger  Today I met my old friend. We used to be so cl...\n",
            "\n",
            "[22065 rows x 2 columns]\n"
          ]
        }
      ],
      "source": [
        "# Filter emotions\n",
        "desired_emotions = ['joy', 'sadness', 'anger']\n",
        "\n",
        "filtered_df = df[df['Emotion'].isin(desired_emotions)]\n",
        "\n",
        "print(filtered_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TOa1eqZ92AyP"
      },
      "outputs": [],
      "source": [
        "# Save the filtered DataFrame to a new CSV file\n",
        "filtered_df.to_csv(filtered_filename, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "F63jutqn2slf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Emotion                                               Text\n",
            "0      joy    Sage Act upgrade on my to do list for tommorow.\n",
            "1  sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
            "2      joy   Such an eye ! The true hazel eye-and so brill...\n",
            "3      joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...\n",
            "4  sadness   .Couldnt wait to see them live. If missing th...\n"
          ]
        }
      ],
      "source": [
        "# load the filtered dataset\n",
        "filtered_df = pd.read_csv(filtered_filename)\n",
        "print(filtered_df.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "UxdRy2bE3eF7"
      },
      "outputs": [],
      "source": [
        "# cleaning the dataset\n",
        "\n",
        "# drop the rows that contain missing values\n",
        "filtered_df.dropna(inplace=True)\n",
        "\n",
        "# Remove duplicate rows\n",
        "filtered_df.drop_duplicates(inplace=True)\n",
        "\n",
        "# save the cleaned dataset\n",
        "filtered_df.to_csv(cleaned_filename, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZlDsa-NO37i8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    Emotion                                               Text\n",
            "0       joy    Sage Act upgrade on my to do list for tommorow.\n",
            "1   sadness  ON THE WAY TO MY HOMEGIRL BABY FUNERAL!!! MAN ...\n",
            "2       joy   Such an eye ! The true hazel eye-and so brill...\n",
            "3       joy  @Iluvmiasantos ugh babe.. hugggzzz for u .!  b...\n",
            "4   sadness   .Couldnt wait to see them live. If missing th...\n",
            "5     anger  The bull tossed the effigy out of their hands ...\n",
            "6   sadness            People hide their behind a #fake smile.\n",
            "7       joy  For once in his life , Leopold must have been ...\n",
            "8     anger   With everything , with everybody , with all t...\n",
            "9   sadness  Shakuhachi dress $580,  10-22 mm lens $708 #pa...\n",
            "10      joy    I have a feeling i will fail french #fuckfrench\n",
            "11      joy                             Good.Let ' s go now . \n",
            "12  sadness    Oh , that's too bad . Should I call a doctor ? \n",
            "13      joy  When I fell in love with \\X\\\".  Overnight I fe...\n",
            "14    anger                           I have to talk to you ! \n",
            "15  sadness  you're so welcome @madelineerich8! so glad I c...\n",
            "16      joy  One could get terribly ecstatic but that would...\n",
            "17  sadness  So much for losing something.. Going to fat bu...\n",
            "18      joy   When I was selected to study here at university.\n",
            "19      joy   Yeah , it â€™ s been ages ! So how have you bee...\n",
            "20      joy  When I passed the B.A exams with first class r...\n",
            "21  sadness  homies all go to ride ponies... I look at them...\n",
            "22  sadness  OMG its December 5th and the windows are open ...\n"
          ]
        }
      ],
      "source": [
        "# load the cleaned dataset\n",
        "print(filtered_df.head(23))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "a9fzMHERBJ72"
      },
      "outputs": [],
      "source": [
        "# split cleaned_emotion_dataset.csv into two sets\n",
        "# 80% for training and 20% for validation dataset.\n",
        "# create the two files, named 'training_dataset.csv' and 'validation_dataset.csv'\n",
        "\n",
        "# reade from the cleaned_emotion_dataset.csv\n",
        "cleaned_df = pd.read_csv(cleaned_filename)\n",
        "\n",
        "X = cleaned_df.drop('Emotion', axis=1)\n",
        "y = cleaned_df['Emotion']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "train_df = pd.concat([X_train, y_train], axis=1)\n",
        "val_df = pd.concat([X_val, y_val], axis=1)\n",
        "\n",
        "train_df.to_csv(training_filename, index=False)\n",
        "val_df.to_csv(validation_filename, index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XulIge9G4SIH"
      },
      "outputs": [],
      "source": [
        "# make .jsonl versions of the validation and training datasets\n",
        "for file in [training_filename, validation_filename]:\n",
        "  df = pd.read_csv(file)\n",
        "  data = df.to_dict(orient='records')\n",
        "  jsonl_string = '\\n'.join([json.dumps(d) for d in data])\n",
        "  jsonl_filename = file.replace('.csv', '.json')\n",
        "  with open(jsonl_filename, 'w') as f:\n",
        "    f.write(jsonl_string)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
